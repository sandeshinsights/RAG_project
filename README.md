 Full-Stack RAG Application

A learning project using Streamlit + FastAPI + LangChain + FAISS

This project is created just for learning purposes — to understand how to build a full-stack RAG (Retrieval-Augmented Generation) application using:

Streamlit → Frontend UI

FastAPI → Backend API

FAISS → Vector database for embeddings

LangChain → Retrieval chain

HuggingFace Embeddings

Gemini LLM (Google Generative AI)

The app allows users to upload or load documents and ask questions based on the content.
A backend RAG pipeline retrieves relevant chunks and sends them to an LLM for the final answer.
